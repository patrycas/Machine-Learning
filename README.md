# Example of Decision Tree using Entropy/Gini Index
In this example we will build a Decision Tree. For that, we must find the feature (or attribute) that split the data in the best way. We use the Impurity Measures, which in this case, we will use Entropy or Gini Index, because we want to show you that using Entropy or Gini Index we will get the same results.
The code is developed in Python and the steps to follow are:

# 1)  Load the Libraries.

# 2)  Load the data. Note that the data is in a JSON format.

# 3) Transform the data.json in a DataFrame using the library: Pandas.

# 4) Entropy or Gini function: Compute the Impurity Measures using Entropy or Gini Index. 

# 5) min_impurity function:Determine the minimum values of Impurity Measures.

# 6) buildTree function: Find the best tree.

For more information you can read the articles:
        https://medium.com/@patriziacastagnod/tree-models-cb676e2cd74f
        
        https://medium.com/@patriziacastagnod/example-compute-the-impurity-using-entropy-and-gini-index-794d101c2c18
